{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **웹 크롤링을 이용한 장바구니 최저가 탐색**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **프로젝트 목표 및 내용**\n",
    "<br>\n",
    "웹 크롤링 작업을 활용해서 각 쇼핑 사이트의 원하는 물건들의 세부 옵션 가격과 배송비 등등을 확인하고 내가 원하는 물품들을 최저의 가격으로 살 수 있는 조건을 찾아주는 프로그램 제작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **주제 선정 이유 또는 이 프로젝트의 필요성**\n",
    "<br>\n",
    "인터넷을 통해 상품을 구매할 때, 같은 상품을 구매하는 경우에 네이버나 다른 쇼핑몰 사이트 등에서 찾은 상품의 가격이 다르고,\n",
    "<br>\n",
    "네이버 쇼핑을 통해 찾아낸 물품의 최저가를 보고 링크를 타고 들어가 봤더니 네이버 쇼핑에 표기된 최저가와 다른 경우도 있기도 하고,\n",
    "<br> \n",
    "또 네이버 쇼핑에서 링크를 통해 쇼핑몰 사이트에 들어갔으나, 쇼핑몰 사이트 내부에서 세부 옵션을 선택해야지만 진짜 가격이 나오는 경우도 있다.\n",
    "<br>\n",
    "그리고 동시에 여러 개의 상품을 구매하는 경우에, 같은 판매자로부터 구매하는 상품은 하나의 배송비로 묶여서 배송이 되기도 한다.\n",
    "<br>\n",
    "하지만 이런 모든 조건들을 고려하여 물품을 구매하는 것은 소비자에게 있어서 상당한 시간을 소모하는 일이기 때문에, 이러한 소비자의 수고를 덜기 위한 프로그램을 제작해 보고자 하였고,\n",
    "<br>\n",
    "파이썬 웹 크롤링 모듈인 beautifulsoup4, selenium 등의 사용법을 익혀 실용적인 프로그램을 만들어 보고자 이러한 주제를 선정하게 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 획득 계획**\n",
    "<br>\n",
    "네이버 쇼핑, 혹은 각 쇼핑몰 사이트(티몬, 위메프 등)에서 검색 결과로 나오는 상품의 상세 페이지에서 가격정보 혹은 구매 옵션이 존재한다면, 구매 옵션과 옵션에 따른 가격정보, 묶음배송 상품정보, 상품명, 상품 이미지 등을 크롤링을 통해 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **구현 계획**\n",
    "<br>\n",
    "프로그램 구현에 필요한 모듈인 beautifulsoup, selenium module을 설치함\n",
    "<br>\n",
    "\n",
    "```python\n",
    "!pip install BeautifulSoup\n",
    "!pip install selenium\n",
    "```\n",
    "\n",
    "<br>\n",
    "프로그램 구현에 필요한 selenium, beautifulsoup, time, request, re module을 각각 import함\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "```\n",
    "\n",
    "<br>\n",
    "버전에 맞는 Chrome webdriver를 설치한 후, 아래 코드를 통해 사용자로부터 가격을 알고자 하는 상품의 이름을 입력받고, 이로부터 각 쇼핑 사이트 검색 결과에서 상품 상세 페이지의 HTML파일을 가져온다.(아래 코드는 네이버쇼핑에 대해 HTML을 가져오는 코드이다.)\n",
    "<br>\n",
    "\n",
    "```python\n",
    "path = \"C:/Users/82106/Downloads/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path) # selenium webdriver.Chrome() 함수를 이용해 크롬 웹드라이버를 실행\n",
    "driver.get(\"https://shopping.naver.com/\") # driver.get() 함수에 네이버 쇼핑 url을 넣어 네이버 쇼핑창을 열기\n",
    "\n",
    "search_box = driver.find_element_by_name(\"query\") # 검색창 찾기\n",
    "item_name = input(prompt = \"찾을 품목 이름 입력 : \") # 검색 품목 이름 입력\n",
    "search_box.send_keys(item_name) # 검색창에 입력한 값 넣기\n",
    "search_box.send_keys(Keys.RETURN) # 검색 버튼 누르기\n",
    "\n",
    "# 동적으로 구현된 웹페이지의 경우 모든 정보가 나오지 않으므로 스크롤해서 모든 정보가 나오게끔 구현    \n",
    "scroll_down_to_lowest_page() # 별도로 만든 함수\n",
    "\n",
    "req = driver.page_source # 현재의 페이지의 HTML 소스코드를 가져옴\n",
    "soup = BeautifulSoup(req, \"lxml\")\n",
    "```\n",
    "구현을 위해 별도로 만든 함수들은 다음과 같다.\n",
    "```python\n",
    "def scroll_down_to_lowest_page():\n",
    "    '''\n",
    "    (void) -> void\n",
    "    \n",
    "    scroll down the page to lowest height\n",
    "    \n",
    "    '''\n",
    "    SCROLL_PAUSE_SEC = 0.5\n",
    "\n",
    "    # 스크롤 높이 가져옴\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # 끝까지 스크롤 다운\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "        # 1초 대기\n",
    "        time.sleep(SCROLL_PAUSE_SEC)\n",
    "    \n",
    "        # 스크롤 다운 후 스크롤 높이 다시 가져옴\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "```\n",
    "<br>\n",
    "먼저, 상품검색을 통해 얻어낸 정보들을 저장할 class를 작성한 후,<br>\n",
    "\n",
    "```python\n",
    "# 검색된 품목의 정보를 저장할 item class 작성\n",
    "class Item:\n",
    "    def __init__(self, item_name, item_URL, item_prices, item_options ,bundle_Shipping_item):\n",
    "        self.__item_name = item_name\n",
    "        self.__item_URL = item_URL\n",
    "        self.__item_prices = item_prices\n",
    "        self.__item_options = item_options\n",
    "        self.__bundle_Shipping_item = bundle_Shipping_item\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"(item) -> str\n",
    "        Return a human-readable string representation of this item.\n",
    "        \"\"\"\n",
    "        rep = \" name: {0}\\n URL: {1}\\n prices: {2}\\n options: {3}\".format(self.__item_name, self.__item_URL, self.__item_prices, self.__item_options)\n",
    "        return rep\n",
    "       \n",
    "```\n",
    "각 상품 상세 페이지에서 상품명, 상품 상세페이지 URL, 상품 가격(구매 옵션 있으면 구매 옵션별 가격), 묶음배송 상품정보 등을 추출함<br>\n",
    "(이때, 쇼핑몰 사이트 별로 추출하는 코드를 각각 구현함)<br>\n",
    "(아래 코드는 네이버 쇼핑에 한해서만 구현)<br>\n",
    "이 중, 상품명, 상품 가격, 상품 상세 페이지 URL을 item class에 저장 후, 사용자에게 보여줌<br>\n",
    "(이때, 상품 가격이 구매 옵션별로 다른 경우 각각의 상품명을 상품명 + 구매 옵션으로 저장 후 각각의 상품 가격을 저장)<br>\n",
    "\n",
    "```python \n",
    "# 각 쇼핑몰의 상품 상세 페이지에서 상품정보가 담긴 attribute를 가져오기\n",
    "def find_value_of_item(soup, items):\n",
    "    \"\"\"\n",
    "    (BeautifulSoup object, item object list) -> void\n",
    "    \n",
    "    extract item data from current product page\n",
    "    \"\"\"\n",
    "    item_name = soup.find(\"(tag_name)\",attrs={\"attribute_name\":\"attribute_value\"})\n",
    "    item_URL = soup.find(\"(tag_name)\",attrs={\"attribute_name\":\"attribute_value\"})    \n",
    "    item_prices = soup.find_all(\"(tag_name)\",attrs={\"attribute_name\":\"attribute_value\"})\n",
    "    item_options = soup.find_all(\"(tag_name)\",attrs={\"attribute_name\":\"attribute_value\"})\n",
    "    \n",
    "    bundle_shipping_items = find_bundle_shipping_item() # 상품 상세페이지에 연결된 묶음배송상품정보 페이지에서 같은 방식으로 추출해서 item object list로 전달\n",
    "    \n",
    "    item = Item(item_name, item_URL, item_prices, item_options, bundle_shipping_item)\n",
    "    items.append(item)\n",
    "```\n",
    "\n",
    "<br>\n",
    "사용자가 검색을 통해 얻은 상품들 중 특정 한 제품만 구매하고 싶은 경우, 다시 검색을 통해서 상품에 대한 정확한 정보를 입력받고, 나온 검색결과를 다시 list로 저장함.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "일련의 과정을 통해서 구매할 상품에 대한 정보를 얻은 후, 구매할 상품이 2개 이상인 경우 묶음배송 상품으로 구매 가능한지 여부를 알아보기 위해 각각의 상품의 묶음배송 상품정보에서 구매하려하는 다른 상품명으로 검색하여 일치하는 상품이 있는지 확인 후, 그 상품에 해당하는 list에 추가함.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "이후, 최저가순으로 나열된 상품정보 list 에서 구매하려는 상품들을 최저가로 구매할 수 있는 조합을 5개까지 추천(기본값, 사용자 설정에 의해 추천하는 구매 조합의 개수를 늘릴 수 있음)<br>\n",
    "추천하는 조합의 개수를 여러개로 설정하는 이유는 가격 외에 구매를 결정하는 다른 조건(리뷰, 구매자 수 등)을 고려하기 위함.<br>\n",
    "(리뷰, 구매자 수 등의 정보는 기록된 URL을 통해 확인)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 문헌\n",
    "<br>\n",
    "python beautifulsoup4 모듈 사용법에 대한 유튜브 강의\n",
    "\n",
    "https://www.youtube.com/watch?v=yQ20jZwDjTE&list=PLR1BBBjlA9ZC94RtCbMnZ6meY_WzOqmiV&index=8&t=6217s \n",
    "\n",
    "selenium documentation\n",
    "\n",
    "https://www.selenium.dev/documentation/en/\n",
    "\n",
    "selenium scroll down 하는 방법\n",
    "\n",
    "https://hello-bryan.tistory.com/194"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
